{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0307f32e-4790-4903-95e4-ebdfdd5ed3f1",
   "metadata": {},
   "source": [
    "# Assignment 2 - Plant Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b257f8-ab38-4b3c-96e5-09f3979b847f",
   "metadata": {},
   "source": [
    "Project Name: COSC102 - Plant Classification <br>\n",
    "Author: - <br>\n",
    "Email: - <br>\n",
    "Date: - <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae471b-ef05-42dc-8bf7-dedc23bde49a",
   "metadata": {},
   "source": [
    "For this project we will be looking at a dataset of plant descriptive variables that were collected at four different locations <br>\n",
    "in the United states. Our task is to train a Classification Machine learning Algorithm that is able to identify which of the four <br>\n",
    "locations a plant was found by using only two features from the dataset collect. We will obviously be trying to first find which <br>\n",
    "two variables return the best results to use, then finding the classification algorithm that best fits the data in our dataset <br>\n",
    "before finally running performance tests on our solution and coming to conclusions on our decisions and choices made throughtout <br>\n",
    "the project. Without further ado... shall we!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "76aa5450-b0ba-4dec-8049-6bb87176cfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    \"\"\"\n",
    "    Reads in a csv file and converts it to a pandas dataframe\n",
    "    Return: Pandas dataframe \n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "plants = load_dataset(\"./Plants_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "85e544ac-6dec-4bfd-91ae-3943e8cc49cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Site        80 non-null     object \n",
      " 1   height      80 non-null     int64  \n",
      " 2   mouth_diam  80 non-null     float64\n",
      " 3   tube_diam   80 non-null     float64\n",
      " 4   keel_diam   80 non-null     float64\n",
      " 5   wingspread  80 non-null     int64  \n",
      " 6   hoodarea    80 non-null     float64\n",
      " 7   wingarea    80 non-null     float64\n",
      " 8   tubearea    80 non-null     float64\n",
      " 9   tubemass_g  80 non-null     float64\n",
      " 10  wingmass_g  80 non-null     float64\n",
      " 11  Ca_ppm      80 non-null     float64\n",
      " 12  P_ppm       80 non-null     float64\n",
      " 13  K_ppm       80 non-null     float64\n",
      " 14  Mg_ppm      80 non-null     float64\n",
      " 15  C_pct       80 non-null     float64\n",
      " 16  H_pct       80 non-null     float64\n",
      " 17  N_pct       80 non-null     float64\n",
      "dtypes: float64(15), int64(2), object(1)\n",
      "memory usage: 11.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check some basic information of our dataset\n",
    "plants.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6edef5-bfb9-4f6a-9c0d-0615ceed8f54",
   "metadata": {},
   "source": [
    "Our data mostly numerical types except for \"Site\" which is type object, since we loaded this data in via a csv, it can only be a string value <br>\n",
    "Another important point to take note of is there is no missing values in our dataset, therefore we won't have to replace any values. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d5050-0376-48a4-9be2-95f6c9b6838d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "04550b04-4d4b-4a28-bac8-0f6d7be23f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now before we go any further we will create a test set of our data\n",
    "# CONVErT THEM TO NUMPY ARRAYS\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(plants.drop(\"Site\", axis=1), plants.Site, test_size=0.25, random_state=42)\n",
    "X_train = X_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21352392-edfc-4de3-8d18-1344fc431ec8",
   "metadata": {},
   "source": [
    "## Load the dataset and partition the dataset in the train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabba0f7-beec-41a1-9f0a-1b65b6aeb0b4",
   "metadata": {},
   "source": [
    "## Select the 2 most higher-performing features based upon cross-validation carried out on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f4acb-264a-447e-b1db-ee17139d3c89",
   "metadata": {},
   "source": [
    "## Construct a confusion matrix based on the classifers performance on the test set and use this to calculate the recall, precision and F1 scores for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50f22ea-49ba-4aa0-b610-b3f97afa63e6",
   "metadata": {},
   "source": [
    "## Construct a ROC curve for each class and calculate the respective AUC values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f5bb6-524c-4abc-8aa5-43b5e014f31a",
   "metadata": {},
   "source": [
    "## Construct a suitable visualisation that demonstrates the decision boundaries learned by the classifer on the features selected through the cross validation process (test data aswell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b813ec-2c68-45ad-9a0e-73501da43120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
