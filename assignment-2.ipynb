{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0307f32e-4790-4903-95e4-ebdfdd5ed3f1",
   "metadata": {},
   "source": [
    "# Assignment 2 - Plant Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b257f8-ab38-4b3c-96e5-09f3979b847f",
   "metadata": {},
   "source": [
    "Project Name: COSC102 - Plant Classification <br>\n",
    "Author: - <br>\n",
    "Email: - <br>\n",
    "Date: - <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae471b-ef05-42dc-8bf7-dedc23bde49a",
   "metadata": {},
   "source": [
    "For this project we will be looking at a dataset of plant descriptive variables that were collected at four different locations <br>\n",
    "in the United states. Our task is to train a Classification Machine learning Algorithm that is able to identify which of the four <br>\n",
    "locations a plant was found by using only two features from the dataset collect. We will obviously be trying to first find which <br>\n",
    "two variables return the best results to use, then finding the classification algorithm that best fits the data in our dataset <br>\n",
    "before finally running performance tests on our solution and coming to conclusions on our decisions and choices made throughtout <br>\n",
    "the project. Without further ado... shall we!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "bac24d97-859a-4712-a828-b318d22a9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f2627-ebf3-4928-b419-dfdc825bf014",
   "metadata": {},
   "source": [
    "## Load the dataset and partition the dataset in the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3cda0d69-0653-4106-9f27-16a9e5630cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to load in csv files.\n",
    "\n",
    "def load_dataset(csv_file_path):\n",
    "    \"\"\" Takes a string of a csv's file path and converts it to a pandas dataframe.\n",
    "    param: String - CSV file path.\n",
    "    return Dataframe - A pandas dataframe.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee77f604-c7b0-447f-8131-7b1a87f2c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path for our data and call the load_dataset function to create our pandas object\n",
    "csv_file_path = \"./Plants_Dataset.csv\"\n",
    "plants = load_dataset(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "503c60b2-238d-4e26-862e-d452a9123072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Site        80 non-null     object \n",
      " 1   height      80 non-null     int64  \n",
      " 2   mouth_diam  80 non-null     float64\n",
      " 3   tube_diam   80 non-null     float64\n",
      " 4   keel_diam   80 non-null     float64\n",
      " 5   wingspread  80 non-null     int64  \n",
      " 6   hoodarea    80 non-null     float64\n",
      " 7   wingarea    80 non-null     float64\n",
      " 8   tubearea    80 non-null     float64\n",
      " 9   tubemass_g  80 non-null     float64\n",
      " 10  wingmass_g  80 non-null     float64\n",
      " 11  Ca_ppm      80 non-null     float64\n",
      " 12  P_ppm       80 non-null     float64\n",
      " 13  K_ppm       80 non-null     float64\n",
      " 14  Mg_ppm      80 non-null     float64\n",
      " 15  C_pct       80 non-null     float64\n",
      " 16  H_pct       80 non-null     float64\n",
      " 17  N_pct       80 non-null     float64\n",
      "dtypes: float64(15), int64(2), object(1)\n",
      "memory usage: 11.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print some basic information about our dataset\n",
    "plants.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6edef5-bfb9-4f6a-9c0d-0615ceed8f54",
   "metadata": {},
   "source": [
    "Our datas mostly numerical types except for \"Site\" which is type object, which will be a string in the abbreviated form of where the specimen was found. <br>\n",
    "An important point to take note of is there is no missing values in our dataset, therefore we won't have to replace any values. Since this assignment <br>\n",
    "call for us to choose the best two performing features from the dataset and use them to plot out our results, we don't have to think too much about how <br>\n",
    "to frame our data or different combinations or statistics we could use to show patterns. We just have to solve the problem that is asked, which is very <br>\n",
    "straight forward and will therefore cut out alot of the thinking. So without wasting anymore precious characters..... lets split up our data and go from there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4d8e0042-3c52-4171-b2a6-29da6400c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLANATION 1 MAYBE USE FOR REPORT\n",
    "# We split the data into two sets, one for training and one for testing. We also have to separate out our labels\n",
    "# since our goal is to train an algorithm that is able to distinguish the site at which a plant is found from two\n",
    "# of it's characteristics, it's obvious that our x set needs to contain all the different types of data we could\n",
    "# train our model with and the y set contain just the labels. Since the site is our labels, we drop the site values\n",
    "# out of our x set and create a y set solely containing the sites. Since our dataset contains 80 plants in total\n",
    "# and the default split size is 25% I won't change this value as that makes a perfect 60/20 split. The universe calls\n",
    "# for me to set the random state to 42.... also because we can control the randomness this way.\n",
    "\n",
    "# EXPLANATION 2 PROBABLY KEEP FOR JUYPTER FILE.\n",
    "# Split our data into the train and test sets. Since we are training an algorithm to learn which site locations our plants are found \n",
    "# we will obviously split our x data points as all the data and our y data points as our labels which only contains the site abbriviations\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(plants.drop(\"Site\", axis=1), plants.Site, random_state=42)\n",
    "\n",
    "# Convert the pandas dataseries to a numpy array for processing\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35065db1-84c6-4770-9160-6fcbd2b4453a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c5ad0c-1e9c-43dd-b310-74097df0ab2a",
   "metadata": {},
   "source": [
    "## Select the 2 most higher-performing features based upon cross-validation carried out on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f1ee56d8-10ec-4ea1-866b-8a21e5af3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a method to sort all of our features and pick the best ones to use\n",
    "\n",
    "# TODO - change this so that I can input any type of classifier in and it will run the project on that classifier\n",
    "\n",
    "def feature_selection(X_value, y_value, f1, f2):\n",
    "    \"\"\"\n",
    "    Takes in an x, y pair of pandas dataset and two integers. It uses the integers as indexes for the X set of data\n",
    "    to slice and only use the features represented by those indexes. It does this by training a classifier on the\n",
    "    sliced data and the y values, then claculates the f1 score and returns the model, and the f1 score.\n",
    "    params: \n",
    "    X_value - a pandas dataset of the x values\n",
    "    y_value - a pandas dataset of the y values\n",
    "    f1 - an integer to be used for slicing\n",
    "    f2 - an integer to be used for slicing\n",
    "    return\n",
    "    \"\"\"\n",
    "\n",
    "    # Create and train our classifier\n",
    "    # svm = SVC()\n",
    "    svm = SGDClassifier(random_state=42)\n",
    "    # svm = KNeighborsClassifier()\n",
    "    svm.fit(X_train[:, [f1,f2]], y_train)\n",
    "\n",
    "    # Calculate our model values\n",
    "    y_train_pred = cross_val_predict(svm, X_value[:, [f1,f2]], y_value, cv=5)\n",
    "    # confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "    # Using macro as we should have an even amount of sites in our dataset\n",
    "    # p = precision_score(y_train, y_train_pred, average=\"macro\",zero_division=1)\n",
    "    # r = recall_score(y_train, y_train_pred, average=\"macro\")\n",
    "    f = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "    # print(f\"features {f1, f2} have a precision {p} recall {r} and f1 score of {f}\") #, round(r[0],4), round(f[0],4)\n",
    "    return f, svm\n",
    "    \n",
    "    # print(type(f1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "08106b99-2cd9-482d-ac20-fa9d988ef478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to scale our data.\n",
    "\n",
    "def scale_data(dataset):\n",
    "    \"\"\"\n",
    "    Takes in a array and uses the sklearns built in scaler function to scale the data in the array\n",
    "    param:\n",
    "    Dataset - an array\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(dataset)\n",
    "\n",
    "# Standardizing our X set, we will do this to our test set later, we also don't need to do this to our y set since it is just labels.\n",
    "scale_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7aa9e371-eece-4994-874c-8f9abefbf400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC()\n",
    "# svm.fit(X_train, y_train)\n",
    "# svm.predict(X_test)\n",
    "\n",
    "# y_pred = cross_val_predict(svm, X_train, y_train, cv=3)\n",
    "# y_test_pred = svm.predict(X_test)\n",
    "\n",
    "# conf = confusion_matrix(y_train, y_pred)\n",
    "# conf_test = confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "234b9c23-4c2a-47e0-bb78-9b515c6604ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b3d7f19b-4997-457b-aac2-6baccc0d14f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 4\n",
      "0 5\n",
      "0 12\n",
      "1 2\n",
      "9 16\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_f2 = 0\n",
    "fugazi = 0\n",
    "# A nested for loop to interate through all combinations of feautures in our data set to send to a function which will determine the most\n",
    "# accurate combination of two to use in our model\n",
    "for feature_1 in range(17):\n",
    "    for feature_2 in range(17):\n",
    "        if feature_1 == feature_2:\n",
    "            continue\n",
    "        poop, model = feature_selection(X_train, y_train, feature_1, feature_2)\n",
    "        \n",
    "        if float(poop) > fugazi:\n",
    "            \n",
    "            fugazi = poop\n",
    "            best_f1 = feature_1\n",
    "            best_f2 = feature_2\n",
    "            svm_clf = model\n",
    "            print(best_f1, best_f2) \n",
    "# TODO triple nest the for loop and make the first loop, loop through different classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c2266-0751-4f97-8cbd-93ec50ff78bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "815ec0d1-3510-4f6c-b824-e8fea9497523",
   "metadata": {},
   "source": [
    "## Construct a confusion matrix based on the classifers performance on the test set and use this to calculate the recall, precision and F1 scores for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8ba2278c-6380-4015-892c-e3abd07c6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c7d6fc48-aa88-45ee-a38e-22f4cdbd9ad7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[177], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ea44f6b7-fbd4-4b12-a68a-08a26cc7af60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5833333333333333\n",
      "Recall: 0.6666666666666666\n",
      "F1: 0.6166666666666667\n"
     ]
    }
   ],
   "source": [
    "# turn this into a function so that I can just call it and input a type of classifier and it outputs the classifiers name and results\n",
    "\n",
    "y_test_processed = svm_clf.predict(X_test[:,[best_f1, best_f2]])\n",
    "confusion_matrix(y_test, y_test_processed)\n",
    "\n",
    "print(f\"Precision: {precision_score(y_test, y_test_processed, average='macro', zero_division=False)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_processed, average='macro')}\")\n",
    "print(f\"F1: {f1_score(y_test, y_test_processed, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed573b-136e-4d91-bcbc-21afbaf6520c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d8a8b-8f78-41db-a806-9b891f0b12e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c50f22ea-49ba-4aa0-b610-b3f97afa63e6",
   "metadata": {},
   "source": [
    "## Construct a ROC curve for each class and calculate the respective AUC values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "df63bd25-0be1-4033-9469-0ed5b4d81406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_score = cross_val_predict(svm_clf, X_train, y_train, cv=3, method=\"decision_function\")\n",
    "# svm_clf.decision_function(X_test[:, [best_f1, best_f2]])\n",
    "\n",
    "# # y_scores = svm.predict_proba(X_test)\n",
    "# # fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "# # roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# # We need to format the y_test into a n_samples x 2 binary array\n",
    "# # that indicates class membership\n",
    "# # y_test_bin = label_binarize(y_score, classes=[0, 1])\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(\"AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2255d4-f47b-4432-b3bc-84083ed06b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f5f5bb6-524c-4abc-8aa5-43b5e014f31a",
   "metadata": {},
   "source": [
    "## Construct a suitable visualisation that demonstrates the decision boundaries learned by the classifer on the features selected through the cross validation process (test data aswell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f389f-fca1-4b60-bf15-ba4720ec1f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e65c81-e72e-4539-a3b0-0fc2641bcdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c619a29d-e045-4298-97a6-1e1e1291d805",
   "metadata": {},
   "source": [
    "27/07/24\n",
    "For two days i've been trying to figure out this project, how to approach it, how to achieve a correct result.... for two days I have wasted my time. Well... wasted is abit strong, every second i spend trying something new i'm learning... be it correct or a mistake, everything is contributing at the moment. I feel very inadequate with datascience at the moment, though after reading through chapters 2 and 3, six or seven times, it's starting to make more sense in my mind. For the last few days I have been trying to create a binary classifier for a dataset that I need to make a multiclassifier for... now this isn't exactly a problem if I knew that, but I didn't so a few things really made no sense. I think i'm starting to come around to being able to fully complete this assignment now.\n",
    "\n",
    "28/07/24\n",
    "So I thought I had figured something out but no... i'm just an idiot. I thought I had to implement a multiclassifier, even though that makes sense to me, the criteria for the assignment doesn't want that... I have to select two features and get the precision, recall, blah blah blah... you don't do that with a multiclassifier, well atleast in my solution I didn't. I did successfully build one for this project.... very quickly too, but it's no good for the assignment, so now i'm back to square one, being very confused about what I have to do. It's not that I don't know what to do or even how to do it, it's the lack of clarity and understanding in all of this, alot seems to be taken for granted in this course at the moment, feel like im teaching myself in all honesty.\n",
    "\n",
    "29/07/24\n",
    "Ok here we go, so i'm coming in fresh with the mind frame of building this in such a way that it could be universal (or close enough) for any dataset you would wanna do this to. I know how to do it (I think), but it's more about implementation.\n",
    "\n",
    "So mid session update and i'm pretty sure im doing it wrong again and I already had it right from days ago.... multiclassifier, just run precision and recall on it after it's trained, run the test data, plot it out and you are done... I think I finished this assignment already but threw it all out thinking I didn't understand.... man I don't understand anything.\n",
    "\n",
    "30/07/24\n",
    "Now we are focusing on finding the two best features, I think I have a solution, though my f1 scores are really low... not sure if that's a me problem, a model selection problem or it is what it is. \n",
    "\n",
    "Ok now im confused, I can't iterate through an SVM to find the feature two features?\n",
    "\n",
    "My mistake, it was but a coding error... I was returning a tuple for my two f1 scores from a function, but i was unable to unpack the variables... this is because i went for dinner and came back and forgot to write that part of the code.... harmless mistake.... harmless shuts down all microsoft computers mistake... just push on commit.\n",
    "\n",
    "Success tonight, after 12 hours in this assignment I finally feel like im on the right track, 3 of the 5 parts down and I should be able to finish the rest of it much faster then this has taken already. I feel after 5 weeks of this class, that im finally coming around to how I need to think to be able to run these note books... what do i mean by that? well, not that im able to do anything in datascience yet, but just that, like normal program, whenever im given a problem, I find it very easy to code a solution, be it some app or even a fullstack backend, frontend, database solution. But  with datascience, ive been struggling to remember that it's just python, and it's just programming, you're just thinking about what you are trying to achieve a little bit differently... anyway i'm rambling. Good session.\n",
    "\n",
    "31/07/24\n",
    "Ok starting today off great, realized I trained the data on a single classifier that had all the data and not trained on two of each feature at a time, meaning that my solution is.... not correct... I will now attempt to fix this...\n",
    "\n",
    "Ok, two minutes later, I think I fixed it, but i gotta be honest.... I feel less and less confident about this project with every passing cell i press shift+enter on.... I don't know if ive done things right and I think this is going to lead to me running multiple classifiers to compare results and see just how wrong or right I am...\n",
    "\n",
    "30 more minutes...... i've done it! and i've written a function so that I can just pass in whatever classifier I want and everything is fit, trained, tested, calculated... you name it. Still have the roc curves and plots to make, but that shouldn't be hard at all (famous last words) \n",
    "\n",
    "Literal famous last words, running into some high headwind at the moment, may have banged my head against the wall enough for one day already (struggling with calculus as it is). Made good progress though, I have a way to run any classifier I want on the dataset, I just need to do a bit of cleaning up and tweaking to allow any classifier without any changing of code or errors. As for roc curves... well, apparently they dont allow for multiclasses, or so it complains at me, though I know that is wrong as I know you can do it, I just gotta figure out how too... for tomorrow, roc curves, pretty plots, then big clean up, document, blah blah blah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c2a7e-7487-4943-bff5-15146b0f768a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
