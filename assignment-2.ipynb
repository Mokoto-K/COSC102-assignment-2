{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0307f32e-4790-4903-95e4-ebdfdd5ed3f1",
   "metadata": {},
   "source": [
    "# Assignment 2 - Plant Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b257f8-ab38-4b3c-96e5-09f3979b847f",
   "metadata": {},
   "source": [
    "Project Name: COSC102 - Plant Classification <br>\n",
    "Author: - <br>\n",
    "Email: - <br>\n",
    "Date: - <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae471b-ef05-42dc-8bf7-dedc23bde49a",
   "metadata": {},
   "source": [
    "For this project we will be looking at a dataset of plant descriptive variables that were collected at four different locations <br>\n",
    "in the United states. Our task is to train a Classification Machine learning Algorithm that is able to identify which of the four <br>\n",
    "locations a plant was found by using only two features from the dataset collect. We will obviously be trying to first find which <br>\n",
    "two variables return the best results to use, then finding the classification algorithm that best fits the data in our dataset <br>\n",
    "before finally running performance tests on our solution and coming to conclusions on our decisions and choices made throughtout <br>\n",
    "the project. Without further ado... shall we!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bac24d97-859a-4712-a828-b318d22a9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f2627-ebf3-4928-b419-dfdc825bf014",
   "metadata": {},
   "source": [
    "## Load the dataset and partition the dataset in the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3cda0d69-0653-4106-9f27-16a9e5630cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to load in csv files.\n",
    "\n",
    "def load_dataset(csv_file_path):\n",
    "    \"\"\" Takes a string of a csv's file path and converts it to a pandas dataframe.\n",
    "    param: String - CSV file path.\n",
    "    return Dataframe - A pandas dataframe.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ee77f604-c7b0-447f-8131-7b1a87f2c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"./Plants_Dataset.csv\"\n",
    "plants = load_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "503c60b2-238d-4e26-862e-d452a9123072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Site        80 non-null     object \n",
      " 1   height      80 non-null     int64  \n",
      " 2   mouth_diam  80 non-null     float64\n",
      " 3   tube_diam   80 non-null     float64\n",
      " 4   keel_diam   80 non-null     float64\n",
      " 5   wingspread  80 non-null     int64  \n",
      " 6   hoodarea    80 non-null     float64\n",
      " 7   wingarea    80 non-null     float64\n",
      " 8   tubearea    80 non-null     float64\n",
      " 9   tubemass_g  80 non-null     float64\n",
      " 10  wingmass_g  80 non-null     float64\n",
      " 11  Ca_ppm      80 non-null     float64\n",
      " 12  P_ppm       80 non-null     float64\n",
      " 13  K_ppm       80 non-null     float64\n",
      " 14  Mg_ppm      80 non-null     float64\n",
      " 15  C_pct       80 non-null     float64\n",
      " 16  H_pct       80 non-null     float64\n",
      " 17  N_pct       80 non-null     float64\n",
      "dtypes: float64(15), int64(2), object(1)\n",
      "memory usage: 11.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print some basic information about our dataset\n",
    "plants.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6edef5-bfb9-4f6a-9c0d-0615ceed8f54",
   "metadata": {},
   "source": [
    "Our datas mostly numerical types except for \"Site\" which is type object, which will be a string in the abbreviated form of where the specimen was found. <br>\n",
    "An important point to take note of is there is no missing values in our dataset, therefore we won't have to replace any values. Since this assignment <br>\n",
    "call for us to choose the best two performing features from the dataset and use them to plot out our results, we don't have to think too much about how <br>\n",
    "to frame our data or different combinations or statistics we could use to show patterns. We just have to solve the problem that is asked, which is very <br>\n",
    "straight forward and will therefore cut out alot of the thinking. So without wasting anymore precious characters..... lets split up our data and go from there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4d8e0042-3c52-4171-b2a6-29da6400c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLANATION 1 MAYBE USE FOR REPORT\n",
    "# We split the data into two sets, one for training and one for testing. We also have to separate out our labels\n",
    "# since our goal is to train an algorithm that is able to distinguish the site at which a plant is found from two\n",
    "# of it's characteristics, it's obvious that our x set needs to contain all the different types of data we could\n",
    "# train our model with and the y set contain just the labels. Since the site is our labels, we drop the site values\n",
    "# out of our x set and create a y set solely containing the sites. Since our dataset contains 80 plants in total\n",
    "# and the default split size is 25% I won't change this value as that makes a perfect 60/20 split. The universe calls\n",
    "# for me to set the random state to 42.... also because we can control the randomness this way.\n",
    "# EXPLANATION 2 PROBABLY KEEP FOR JUYPTER FILE.\n",
    "# Split our data into the train and test sets. Since we are training an algorithm to learn which site locations our plants are found \n",
    "# we will obviously split our x data points as all the data and our y data points as our labels which only contains the site abbriviations\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(plants.drop(\"Site\", axis=1), plants.Site, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35065db1-84c6-4770-9160-6fcbd2b4453a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8c5ad0c-1e9c-43dd-b310-74097df0ab2a",
   "metadata": {},
   "source": [
    "## Select the 2 most higher-performing features based upon cross-validation carried out on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f1ee56d8-10ec-4ea1-866b-8a21e5af3c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(model, X_value, y_value, f1, f2):\n",
    "    \"\"\"\n",
    "    param\n",
    "    return\n",
    "    \"\"\"\n",
    "    y_train_pred = cross_val_predict(model, X_value[:, [f1,f2]], y_value, cv=5)\n",
    "    confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "    # Using macro as we should have an even amount of sites in our dataset\n",
    "    p = precision_score(y_train, y_train_pred, average=\"macro\",zero_division=1)\n",
    "    r = recall_score(y_train, y_train_pred, average=\"macro\")\n",
    "    f = f1_score(y_train, y_train_pred, average=\"macro\")\n",
    "    # print(f\"features {f1, f2} have a precision {p} recall {r} and f1 score of {f}\") #, round(r[0],4), round(f[0],4)\n",
    "    return f\n",
    "    \n",
    "    # print(type(f1))\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "08106b99-2cd9-482d-ac20-fa9d988ef478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(dataset):\n",
    "    \"\"\"\n",
    "    param\n",
    "    return\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(dataset)\n",
    "\n",
    "# Standardizing our X set, we will do this to our test set later, we also don't need to do this to our y set since it is just labels.\n",
    "scale_data(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7aa9e371-eece-4994-874c-8f9abefbf400",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "# svm.predict(X_test)\n",
    "\n",
    "y_pred = cross_val_predict(svm, X_train, y_train, cv=3)\n",
    "y_test_pred = svm.predict(X_test)\n",
    "\n",
    "conf = confusion_matrix(y_train, y_pred)\n",
    "conf_test = confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "234b9c23-4c2a-47e0-bb78-9b515c6604ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataseries to a numpy array for processing\n",
    "X_train = X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b3d7f19b-4997-457b-aac2-6baccc0d14f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_f2 = 0\n",
    "fugazi = 0\n",
    "# A nested for loop to interate through all combinations of feautures in our data set to send to a function which will determine the most\n",
    "# accurate combination of two to use in our model\n",
    "for feature_1 in range(17):\n",
    "    for feature_2 in range(17):\n",
    "        if feature_1 == feature_2:\n",
    "            continue\n",
    "        poop = feature_selection(svm, X_train, y_train, feature_1, feature_2)\n",
    "        if float(poop) > fugazi:\n",
    "            \n",
    "            fugazi = poop\n",
    "            best_f1 = feature_1\n",
    "            best_f2 = feature_2\n",
    "            \n",
    "print(best_f1, best_f2)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c2266-0751-4f97-8cbd-93ec50ff78bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "815ec0d1-3510-4f6c-b824-e8fea9497523",
   "metadata": {},
   "source": [
    "## Construct a confusion matrix based on the classifers performance on the test set and use this to calculate the recall, precision and F1 scores for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2278c-6380-4015-892c-e3abd07c6879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44f6b7-fbd4-4b12-a68a-08a26cc7af60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed573b-136e-4d91-bcbc-21afbaf6520c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d8a8b-8f78-41db-a806-9b891f0b12e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c50f22ea-49ba-4aa0-b610-b3f97afa63e6",
   "metadata": {},
   "source": [
    "## Construct a ROC curve for each class and calculate the respective AUC values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f4acb-264a-447e-b1db-ee17139d3c89",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2255d4-f47b-4432-b3bc-84083ed06b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f5f5bb6-524c-4abc-8aa5-43b5e014f31a",
   "metadata": {},
   "source": [
    "## Construct a suitable visualisation that demonstrates the decision boundaries learned by the classifer on the features selected through the cross validation process (test data aswell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f389f-fca1-4b60-bf15-ba4720ec1f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e65c81-e72e-4539-a3b0-0fc2641bcdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c619a29d-e045-4298-97a6-1e1e1291d805",
   "metadata": {},
   "source": [
    "27/07/24\n",
    "For two days i've been trying to figure out this project, how to approach it, how to achieve a correct result.... for two days I have wasted my time. Well... wasted is abit strong, ever second i spent trying something new i'm learning... be it correct or a mistake, everything is contributing at the moment. I feel very inadequate with datascience at the moment, though after reading through chapters 2 and 3, six or seven times, it's starting to make more sense in my mind. For the last few days I have been trying to create a binary classifier for a dataset that I need to make a multiclassifier for... now this isn't exactly a problem if I knew that, but I didn't so a few things really made no sense. I think i'm starting to come around to being able to fully complete this assignment now.\n",
    "\n",
    "28/07/24\n",
    "So I thought I had figured something out but no... i'm just an idiot. I thought I had to implement a multiclassifier, even though that makes sense to me, the criteria for the assignment doesn't want that... I have to select two features and get the precision, recall, blah blah blah... you don't do that with a multiclassifier, well atleast in my solution I didn't. I did successfully build one for this project.... very quickly too, but it's no good for the assignment, so now i'm back to square one, being very confused about what I have to do. It's not that I don't know what to do or even how to do it, it's the lack of clarity and understanding in all of this, alot seems to be taken for granted in this course at the moment, feel like im teaching myself in all honesty.\n",
    "\n",
    "29/07/24\n",
    "Ok here we go, so i'm coming in fresh with the mind frame of building this in such a way that it could be universal (or close enough) for any dataset you would wanna do this to. I know how to do it (I think), but it's more about implementation.\n",
    "\n",
    "So mid session update and i'm pretty sure im doing it wrong again and I already had it right from days ago.... multiclassifier, just run precision and recall on it after it's trained, run the test data, plot it out and you are done... I think I finished this assignment already but threw it all out thinking I didn't understand.... man I don't understand anything.\n",
    "\n",
    "30/07/24\n",
    "Now we are focusing on finding the two best features, I think I have a solution, though my f1 scores are really low... not sure if that's a me problem, a model selection problem or it is what it is. \n",
    "\n",
    "Ok now im confused, I can't iterate through an SVM to find the feature two features?\n",
    "\n",
    "My mistake, it was but a coding error... I was returning a tuple for my two f1 scores from a function, but i was unable to unpack the variables... this is because i went for dinner and came back and forgot to write that part of the code.... harmless mistake.... harmless shuts down all microsoft computers mistake... just push on commit.\n",
    "\n",
    "Success tonight, after 12 hours in this assignment I finally feel like im on the right track, 3 of the 5 parts down and I should be able to finish the rest of it much faster then this has taken already. I feel after 5 weeks of this class, that im finally coming around to how I need to think to be able to run these note books... what do i mean by that? well, not that im able to do anything in datascience yet, but just that, like normal program, whenever im given a problem, I find it very easy to code a solution, be it some app or even a fullstack backend, frontend, database solution. But  with datascience, ive been struggling to remember that it's just python, and it's just programming, you're just thinking about what you are trying to achieve a little bit differently... anyway i'm rambling. Good session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c2a7e-7487-4943-bff5-15146b0f768a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
